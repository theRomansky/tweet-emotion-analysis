{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:17.397475Z",
     "start_time": "2024-03-23T11:45:17.393615Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import spacy\n",
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ознакомимся с нашим набором данных\n",
    "df = pd.read_csv('../data/text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:18.023592Z",
     "start_time": "2024-03-23T11:45:17.574907Z"
    }
   },
   "id": "a75fd38487fd32ed",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Загрузка списка из файла\n",
    "with open('tokenized_text.pkl', 'rb') as f:\n",
    "    tokenized_text = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:18.737424Z",
     "start_time": "2024-03-23T11:45:18.024654Z"
    }
   },
   "id": "eb62ab4512cf1a37",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# буду использовать word2vec для эмбеддинга\n",
    "w2v_model = Word2Vec(tokenized_text, vector_size=100, workers=4)\n",
    "# Получу векторные представления слов для каждого документа и усредняю веркторы в документе. Сохраняю индексы документов, для которых не нашлось векторных представлений слов\n",
    "empty_doc_indexes = []\n",
    "document_vectors = []\n",
    "for index, document in enumerate(tokenized_text):\n",
    "    doc_vectors = [w2v_model.wv[word] for word in document if word in w2v_model.wv]\n",
    "\n",
    "    if doc_vectors:\n",
    "        avg_doc_vector = np.mean(doc_vectors, axis=0)\n",
    "        document_vectors.append(avg_doc_vector)\n",
    "    else:\n",
    "        empty_doc_indexes.append(index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.318249Z",
     "start_time": "2024-03-23T11:45:22.163028Z"
    }
   },
   "id": "630df77965923bce",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Удалю метки для документов, слова в которых не получили векторное представление\n",
    "labels_list = df['label'].values.tolist()\n",
    "for index in sorted(empty_doc_indexes, reverse=True):\n",
    "    labels_list.pop(index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.325102Z",
     "start_time": "2024-03-23T11:45:34.319251Z"
    }
   },
   "id": "6e86b84fa372df3c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Создаю тензоры для данных и их меток\n",
    "document_vectors_np = np.array(document_vectors)\n",
    "document_vectors_tensor = torch.tensor(document_vectors_np)\n",
    "labels_tensor = torch.tensor(labels_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.470904Z",
     "start_time": "2024-03-23T11:45:34.326027Z"
    }
   },
   "id": "27a9c89604056cf3",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Делю данные на тренировочные и тестовые/валидационные\n",
    "train_data, test_val_data, train_labels, test_val_labels = train_test_split(document_vectors_tensor, labels_tensor, train_size=0.7, random_state=24, stratify=labels_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.584642Z",
     "start_time": "2024-03-23T11:45:34.472686Z"
    }
   },
   "id": "a344a725dae7582",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Разделяю тестовые/валидационные на тестовые и валидационные\n",
    "test_data, val_data, test_labels, val_labels = train_test_split(test_val_data, test_val_labels, train_size=0.5, random_state=24, stratify=test_val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.619624Z",
     "start_time": "2024-03-23T11:45:34.585642Z"
    }
   },
   "id": "443916336599c4b3",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Стандартизую данные\n",
    "mean = torch.mean(train_data, dim=0)\n",
    "std = torch.std(train_data, dim=0)\n",
    "train_data = (train_data - mean) / std\n",
    "test_data = (test_data - mean) / std\n",
    "val_data = (val_data - mean) / std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.757960Z",
     "start_time": "2024-03-23T11:45:34.620557Z"
    }
   },
   "id": "d3b2bacd129d235e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Создаю измерение батчей\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "val_dataset = TensorDataset(val_data, val_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.763613Z",
     "start_time": "2024-03-23T11:45:34.759457Z"
    }
   },
   "id": "7d4d008ca7b1d2e5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Получение вывода только из последнего временного шага\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.771902Z",
     "start_time": "2024-03-23T11:45:34.764723Z"
    }
   },
   "id": "a3f3181b431d0056",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, criterion, train_loader, val_loader=None):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_train = 0.0\n",
    "        for data, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        avg_loss_train = loss_train / len(train_loader)\n",
    "        train_losses.append(avg_loss_train)\n",
    "\n",
    "        if val_loader is not None:\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_data, val_labels in val_loader:\n",
    "                    val_outputs = model(val_data)\n",
    "                    val_loss += criterion(val_outputs, val_labels).item()\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Вывод средней потери на каждой эпохе\n",
    "        if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss: {:.4f}'.format(\n",
    "                datetime.datetime.now(), epoch + 1, avg_loss_train))\n",
    "            if val_loader is not None:\n",
    "                print('{} Epoch {}, Validation loss: {:.4f}'.format(\n",
    "                    datetime.datetime.now(), epoch + 1, avg_val_loss))\n",
    "\n",
    "    return train_losses, val_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.777905Z",
     "start_time": "2024-03-23T11:45:34.773263Z"
    }
   },
   "id": "23ec0e43dc1bf2a8",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses=None):\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    if val_losses:\n",
    "        plt.plot(val_losses, label='Validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:34.784352Z",
     "start_time": "2024-03-23T11:45:34.781645Z"
    }
   },
   "id": "3e996ae908b8d2e6",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Параметры модели\n",
    "input_size = 100  # Размер входного вектора\n",
    "hidden_size = 128  # Размер скрытого состояния LSTM\n",
    "num_layers = 2  # Количество слоев LSTM\n",
    "num_classes = 6  # Количество классов\n",
    "learning_rate = 0.001\n",
    "n_epochs = 15\n",
    "\n",
    "# Инициализация модели\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:35.358Z",
     "start_time": "2024-03-23T11:45:34.785717Z"
    }
   },
   "id": "90ffc854945c753b",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_losses, val_losses \u001B[38;5;241m=\u001B[39m \u001B[43mtraining_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 9\u001B[0m, in \u001B[0;36mtraining_loop\u001B[0;34m(n_epochs, optimizer, model, criterion, train_loader, val_loader)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data, labels \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m      8\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     11\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/DataspellProjects/twit_sentiment/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/twit_sentiment/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[12], line 13\u001B[0m, in \u001B[0;36mLSTMModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     10\u001B[0m h0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     11\u001B[0m c0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 13\u001B[0m out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mh0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc0\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Получение вывода только из последнего временного шага\u001B[39;00m\n\u001B[1;32m     16\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(out[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :])\n",
      "File \u001B[0;32m~/DataspellProjects/twit_sentiment/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/DataspellProjects/twit_sentiment/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/DataspellProjects/twit_sentiment/venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:870\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    867\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m hx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m    868\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor unbatched 2-D input, hx and cx should \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    869\u001B[0m                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malso be 2-D but got (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-D, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-D) tensors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 870\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[1;32m    871\u001B[0m     hx \u001B[38;5;241m=\u001B[39m (hx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), hx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    872\u001B[0m \u001B[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001B[39;00m\n\u001B[1;32m    873\u001B[0m \u001B[38;5;66;03m# the user believes he/she is passing in.\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = training_loop(n_epochs, optimizer, model, criterion, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:35.702415Z",
     "start_time": "2024-03-23T11:45:35.358953Z"
    }
   },
   "id": "3e88f8b21921daa8",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:45:35.703209Z",
     "start_time": "2024-03-23T11:45:35.703148Z"
    }
   },
   "id": "26c953a94442b209"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_data, val_labels in val_loader:\n",
    "        val_outputs = model(val_data)\n",
    "        val_loss += criterion(val_outputs, val_labels).item()\n",
    "        _, predicted = torch.max(val_outputs, 1)\n",
    "        total += val_labels.size(0)\n",
    "        correct += (predicted == val_labels).sum().item()\n",
    "\n",
    "print('Validation loss: {:.4f}'.format(val_loss / len(val_loader)))\n",
    "print('Validation accuracy: {:.2f}%'.format(100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d8d9c62bd123793"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_data, test_labels in test_loader:\n",
    "        test_outputs = model(test_data)\n",
    "        test_loss += criterion(test_outputs, test_labels).item()\n",
    "        _, predicted = torch.max(test_outputs, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "print('Test loss: {:.4f}'.format(test_loss / len(test_loader)))\n",
    "print('Test accuracy: {:.2f}%'.format(100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3083f6cf721ba229"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
