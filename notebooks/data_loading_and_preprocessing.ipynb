{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:16.893926Z",
     "start_time": "2024-04-06T08:11:16.891047Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Ознакомимся с нашим набором данных\n",
    "df = pd.read_csv('../data/text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.384057Z",
     "start_time": "2024-04-06T08:11:16.923195Z"
    }
   },
   "id": "b2259c973361b92a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each entry in this dataset consists of a text segment representing a Twitter message and a corresponding label indicating the predominant emotion conveyed. The emotions are classified into six categories: sadness (0), joy (1), love (2), anger (3), fear (4), and surprise (5). Whether you're interested in sentiment analysis, emotion classification, or text mining, this dataset provides a rich foundation for exploring the nuanced emotional landscape within the realm of social media."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8491dda59307f54"
  },
  {
   "cell_type": "code",
   "source": [
    "# проверим соотношение классов\n",
    "df['label'].value_counts() / len(df['label']) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.390855Z",
     "start_time": "2024-04-06T08:11:17.385273Z"
    }
   },
   "id": "dfac5105c634707d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    33.844519\n",
       "0    29.074948\n",
       "3    13.751383\n",
       "4    11.446970\n",
       "2     8.290128\n",
       "5     3.592053\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "df = df.drop(['Unnamed: 0'], axis=1)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.402445Z",
     "start_time": "2024-04-06T08:11:17.391855Z"
    }
   },
   "id": "5dcd8c0adb9c7a6a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# мой сет с которым я буду работать\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.408711Z",
     "start_time": "2024-04-06T08:11:17.404175Z"
    }
   },
   "id": "7deca1fc0139fb57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text  label\n",
       "0           i just feel really helpless and heavy hearted      4\n",
       "1       ive enjoyed being able to slouch about relax a...      0\n",
       "2       i gave up my internship with the dmrg and am f...      4\n",
       "3                              i dont know i feel so lost      0\n",
       "4       i am a kindergarten teacher and i am thoroughl...      4\n",
       "...                                                   ...    ...\n",
       "416804  i feel like telling these horny devils to find...      2\n",
       "416805  i began to realize that when i was feeling agi...      3\n",
       "416806  i feel very curious be why previous early dawn...      5\n",
       "416807  i feel that becuase of the tyranical nature of...      3\n",
       "416808  i think that after i had spent some time inves...      5\n",
       "\n",
       "[416809 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416804</th>\n",
       "      <td>i feel like telling these horny devils to find...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416805</th>\n",
       "      <td>i began to realize that when i was feeling agi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416806</th>\n",
       "      <td>i feel very curious be why previous early dawn...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416807</th>\n",
       "      <td>i feel that becuase of the tyranical nature of...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416808</th>\n",
       "      <td>i think that after i had spent some time inves...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416809 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# проверим наличие верхнего регистра в тексте\n",
    "mask_uppercase = df['text'].str.isupper()\n",
    "df[mask_uppercase]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.443313Z",
     "start_time": "2024-04-06T08:11:17.409523Z"
    }
   },
   "id": "37bed8a4e41295dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# проверим наличие упоминаний пользователей. Сначала создам функцию\n",
    "def check_user_mentions(text):\n",
    "    pattern = r'@(\\w+)'\n",
    "    mentions = re.findall(pattern, text)\n",
    "    return mentions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.446284Z",
     "start_time": "2024-04-06T08:11:17.444177Z"
    }
   },
   "id": "8a469c236eb67a7a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "mentions = []\n",
    "for twit in df['text']:\n",
    "    if len(check_user_mentions(twit)) > 0:\n",
    "        mentions.append(twit)\n",
    "        \n",
    "print(mentions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.660901Z",
     "start_time": "2024-04-06T08:11:17.447019Z"
    }
   },
   "id": "4e41c54d5ea1ea18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Исправляю сокращённые формы, которые могут быть неправильно обработаны токенизатором и лемматизатором spaCy\n",
    "def expand_contractions(text):\n",
    "    contractions = {\n",
    "        \"im\": \"i am\",\n",
    "        \"i m\": \"i am\",\n",
    "        \"i ll\": \"i will\",\n",
    "        \"i ve\": \"i have\",\n",
    "        \"ive\": \"i have\",\n",
    "        \"i d\": \"i would\",\n",
    "        \"id\": \"i would\",\n",
    "        \"youre\": \"you are\",\n",
    "        \"you re\": \"you are\",\n",
    "        \"youll\": \"you will\",\n",
    "        \"you ll\": \"you will\",\n",
    "        \"youve\": \"you have\",\n",
    "        \"you ve\": \"you have\",\n",
    "        \"youd\": \"you would\",\n",
    "        \"you d\": \"you would\",\n",
    "        \"hes\": \"he is\",\n",
    "        \"he s\": \"he is\",\n",
    "        \"he ll\": \"he will\",\n",
    "        \"he d\": \"he would\",\n",
    "        \"hed\": \"he would\",\n",
    "        \"shes\": \"she is\",\n",
    "        \"she s\": \"she is\",\n",
    "        \"she ll\": \"she will\",\n",
    "        \"shell\": \"she will\",\n",
    "        \"she d\": \"she would\",\n",
    "        \"shed\": \"she would\",\n",
    "        \"it s\": \"it is\",\n",
    "        \"it d\": \"it would\",\n",
    "        \"itd\": \"it would\",\n",
    "        \"we re\": \"we are\",\n",
    "        \"we ll\": \"we will\",\n",
    "        \"we ve\": \"we have\",\n",
    "        \"weve\": \"we have\",\n",
    "        \"we d\": \"we would\",\n",
    "        \"wed\": \"we would\",\n",
    "        \"they re\": \"they are\",\n",
    "        \"theyre\": \"they are\",\n",
    "        \"theyll\": \"they will\",\n",
    "        \"they ll\": \"they will\",\n",
    "        \"they ve\": \"they have\",\n",
    "        \"theyve\": \"they have\",\n",
    "        \"theyd\": \"they would\",\n",
    "        \"they d\": \"they would\",\n",
    "        \"don t\": \"do not\",\n",
    "        \"dont\": 'do not',\n",
    "        \"doesn t\": \"does not\",\n",
    "        \"didn t\": \"did not\",\n",
    "        \"didnt\": \"did not\",\n",
    "        \"haven t\": \"have not\",\n",
    "        \"hasn t\": \"has not\",\n",
    "        \"hadn t t\": \"had not\",\n",
    "        \"wouldn t\": \"would not\",\n",
    "        \"won t\": \"will not\",\n",
    "        \"wont\": \"will not\",\n",
    "        \"can t\": \"can not\",\n",
    "        \"cant\": \"can not\",\n",
    "        \"couldn t t\": \"could not\",\n",
    "        \"couldnt\": \"could not\",\n",
    "        \"shouldn t\": \"should not\",\n",
    "        \"shouldnt\": \"should not\",\n",
    "        \"isn t\": \"is not\",\n",
    "        \"isnt\": \"is not\",\n",
    "        \"weren t\": \"were not\",\n",
    "        \"werent\": \"were not\",\n",
    "        \"wasn t\": \"was not\",\n",
    "        \"wasnt\": \"was not\",\n",
    "        \"aren t\": \"are not\",\n",
    "        \"arent\": \"are not\",\n",
    "        \"woulndnt t ve\": \"would not have\",\n",
    "        \"woulndnttve\": \"would not have\",\n",
    "        \"shoulndnt t ve\": \"should not have\",\n",
    "        \"shoulndnttve\": \"should not have\"\n",
    "    }\n",
    "\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = re.sub(r'\\b' + re.escape(contraction) + r'\\b', expansion, text)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:11:17.667339Z",
     "start_time": "2024-04-06T08:11:17.661899Z"
    }
   },
   "id": "43f8031edb212b2b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# Применяю функцию. Сохраняю результат в тот же датасет, заменив оригинальные данные обработанными\n",
    "df['text'] = df['text'].apply(expand_contractions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:12:17.735740Z",
     "start_time": "2024-04-06T08:11:17.668254Z"
    }
   },
   "id": "7e34c731b01a3842",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# для удаления стоп-слов и токенизации буду использовать пакет SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:12:18.061253Z",
     "start_time": "2024-04-06T08:12:17.737844Z"
    }
   },
   "id": "192c742c37b177aa",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# определяю функцию, которая будет возвращать леммы без стоп-слов\n",
    "def process_text_with_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if not token.is_stop]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:12:18.064193Z",
     "start_time": "2024-04-06T08:12:18.062003Z"
    }
   },
   "id": "495ddae0b3c06e44",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# вызываю написанную выше функцию и получаю список списков с обработанным текстом\n",
    "tokenized_text = []\n",
    "\n",
    "for text in df['text']:\n",
    "    token = process_text_with_spacy(text)\n",
    "    tokenized_text.append(token)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:45:16.723389Z",
     "start_time": "2024-04-06T08:12:18.065175Z"
    }
   },
   "id": "a3993816de65e484",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# Сохранение списка в файл\n",
    "with open('../data/tokenized_text.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_text, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:45:17.330072Z",
     "start_time": "2024-04-06T08:45:16.724237Z"
    }
   },
   "id": "dcecd9e5322b0cbd",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:45:17.332139Z",
     "start_time": "2024-04-06T08:45:17.330794Z"
    }
   },
   "id": "fd5627c4159b1466",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
