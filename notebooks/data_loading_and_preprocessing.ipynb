{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:08:34.970715Z",
     "start_time": "2024-03-23T11:08:32.803134Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import spacy\n",
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ознакомимся с нашим набором данных\n",
    "df = pd.read_csv('../data/text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T11:08:35.455488Z",
     "start_time": "2024-03-23T11:08:34.972056Z"
    }
   },
   "id": "b2259c973361b92a",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each entry in this dataset consists of a text segment representing a Twitter message and a corresponding label indicating the predominant emotion conveyed. The emotions are classified into six categories: sadness (0), joy (1), love (2), anger (3), fear (4), and surprise (5). Whether you're interested in sentiment analysis, emotion classification, or text mining, this dataset provides a rich foundation for exploring the nuanced emotional landscape within the realm of social media."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8491dda59307f54"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "label\n1    33.844519\n0    29.074948\n3    13.751383\n4    11.446970\n2     8.290128\n5     3.592053\nName: count, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим соотношение классов\n",
    "df['label'].value_counts() / len(df['label']) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T06:59:35.607960Z",
     "start_time": "2024-03-23T06:59:35.601222Z"
    }
   },
   "id": "dfac5105c634707d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# так как производительности моего компьютера не хватает для обработки такого количества данных, я возьму только 10% данных с таким-же соотношением классов\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T06:59:37.381552Z",
     "start_time": "2024-03-23T06:59:36.714722Z"
    }
   },
   "id": "5dcd8c0adb9c7a6a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     text  label\n0           i just feel really helpless and heavy hearted      4\n1       ive enjoyed being able to slouch about relax a...      0\n2       i gave up my internship with the dmrg and am f...      4\n3                              i dont know i feel so lost      0\n4       i am a kindergarten teacher and i am thoroughl...      4\n...                                                   ...    ...\n416804  i feel like telling these horny devils to find...      2\n416805  i began to realize that when i was feeling agi...      3\n416806  i feel very curious be why previous early dawn...      5\n416807  i feel that becuase of the tyranical nature of...      3\n416808  i think that after i had spent some time inves...      5\n\n[416809 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i just feel really helpless and heavy hearted</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ive enjoyed being able to slouch about relax a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i gave up my internship with the dmrg and am f...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i dont know i feel so lost</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am a kindergarten teacher and i am thoroughl...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>416804</th>\n      <td>i feel like telling these horny devils to find...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>416805</th>\n      <td>i began to realize that when i was feeling agi...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>416806</th>\n      <td>i feel very curious be why previous early dawn...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>416807</th>\n      <td>i feel that becuase of the tyranical nature of...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>416808</th>\n      <td>i think that after i had spent some time inves...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>416809 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# мой сабсет с которым я буду работать\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T05:22:21.185031Z",
     "start_time": "2024-03-23T05:22:21.179808Z"
    }
   },
   "id": "7deca1fc0139fb57",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# проверим наличие верхнего регистра в тексте\n",
    "mask_uppercase = df['text'].str.isupper()\n",
    "df[mask_uppercase]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37bed8a4e41295dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# проверим наличие упоминаний пользователей. Сначала создам функцию\n",
    "def check_user_mentions(text):\n",
    "    pattern = r'@(\\w+)'\n",
    "    mentions = re.findall(pattern, text)\n",
    "    return mentions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a469c236eb67a7a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mentions = []\n",
    "for twit in df['text']:\n",
    "    if len(check_user_mentions(twit)) > 0:\n",
    "        mentions.append(twit)\n",
    "        \n",
    "print(mentions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e41c54d5ea1ea18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Исправляю сокращённые формы, которые могут быть неправильно обработаны токенизатором и лемматизатором spaCy\n",
    "def expand_contractions(text):\n",
    "    contractions = {\n",
    "        \"im\": \"i am\",\n",
    "        \"i m\": \"i am\",\n",
    "        \"i ll\": \"i will\",\n",
    "        \"i ve\": \"i have\",\n",
    "        \"ive\": \"i have\",\n",
    "        \"i d\": \"i would\",\n",
    "        \"id\": \"i would\",\n",
    "        \"youre\": \"you are\",\n",
    "        \"you re\": \"you are\",\n",
    "        \"youll\": \"you will\",\n",
    "        \"you ll\": \"you will\",\n",
    "        \"youve\": \"you have\",\n",
    "        \"you ve\": \"you have\",\n",
    "        \"youd\": \"you would\",\n",
    "        \"you d\": \"you would\",\n",
    "        \"hes\": \"he is\",\n",
    "        \"he s\": \"he is\",\n",
    "        \"he ll\": \"he will\",\n",
    "        \"he d\": \"he would\",\n",
    "        \"hed\": \"he would\",\n",
    "        \"shes\": \"she is\",\n",
    "        \"she s\": \"she is\",\n",
    "        \"she ll\": \"she will\",\n",
    "        \"shell\": \"she will\",\n",
    "        \"she d\": \"she would\",\n",
    "        \"shed\": \"she would\",\n",
    "        \"it s\": \"it is\",\n",
    "        \"it d\": \"it would\",\n",
    "        \"itd\": \"it would\",\n",
    "        \"we re\": \"we are\",\n",
    "        \"we ll\": \"we will\",\n",
    "        \"we ve\": \"we have\",\n",
    "        \"weve\": \"we have\",\n",
    "        \"we d\": \"we would\",\n",
    "        \"wed\": \"we would\",\n",
    "        \"they re\": \"they are\",\n",
    "        \"theyre\": \"they are\",\n",
    "        \"theyll\": \"they will\",\n",
    "        \"they ll\": \"they will\",\n",
    "        \"they ve\": \"they have\",\n",
    "        \"theyve\": \"they have\",\n",
    "        \"theyd\": \"they would\",\n",
    "        \"they d\": \"they would\",\n",
    "        \"don t\": \"do not\",\n",
    "        \"dont\": 'do not',\n",
    "        \"doesn t\": \"does not\",\n",
    "        \"didn t\": \"did not\",\n",
    "        \"didnt\": \"did not\",\n",
    "        \"haven t\": \"have not\",\n",
    "        \"hasn t\": \"has not\",\n",
    "        \"hadn t t\": \"had not\",\n",
    "        \"wouldn t\": \"would not\",\n",
    "        \"won t\": \"will not\",\n",
    "        \"wont\": \"will not\",\n",
    "        \"can t\": \"can not\",\n",
    "        \"cant\": \"can not\",\n",
    "        \"couldn t t\": \"could not\",\n",
    "        \"couldnt\": \"could not\",\n",
    "        \"shouldn t\": \"should not\",\n",
    "        \"shouldnt\": \"should not\",\n",
    "        \"isn t\": \"is not\",\n",
    "        \"isnt\": \"is not\",\n",
    "        \"weren t\": \"were not\",\n",
    "        \"werent\": \"were not\",\n",
    "        \"wasn t\": \"was not\",\n",
    "        \"wasnt\": \"was not\",\n",
    "        \"aren t\": \"are not\",\n",
    "        \"arent\": \"are not\",\n",
    "        \"woulndnt t ve\": \"would not have\",\n",
    "        \"woulndnttve\": \"would not have\",\n",
    "        \"shoulndnt t ve\": \"should not have\",\n",
    "        \"shoulndnttve\": \"should not have\"\n",
    "    }\n",
    "\n",
    "    for contraction, expansion in contractions.items():\n",
    "        text = re.sub(r'\\b' + re.escape(contraction) + r'\\b', expansion, text)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43f8031edb212b2b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Применяю функцию. Сохраняю результат в тот же датасет, заменив оригинальные данные обработанными\n",
    "df['text'] = df['text'].apply(expand_contractions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e34c731b01a3842",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# для удаления стоп-слов и токенизации буду использовать пакет SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "192c742c37b177aa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# определяю функцию, которая будет возвращать леммы без стоп-слов\n",
    "def process_text_with_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc if not token.is_stop]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "495ddae0b3c06e44",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# вызываю написанную выше функцию и получаю список списков с обработанным текстом\n",
    "tokenized_text = []\n",
    "\n",
    "for text in df['text']:\n",
    "    token = process_text_with_spacy(text)\n",
    "    tokenized_text.append(token)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3993816de65e484",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Сохранение списка в файл\n",
    "with open('..data/tokenized_text.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_text, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcecd9e5322b0cbd",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
